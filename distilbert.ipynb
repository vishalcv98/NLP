{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c306fc",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ee856907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from contractions import contractions_dict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sia\n",
    "import transformers\n",
    "from transformers import pipeline \n",
    "from transformers import DistilBertTokenizerFast\n",
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a04359",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7f1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = pd.read_csv('bert_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca62f6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>private patio balcony bbq area business cente...</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bedroom  code link post totally remodeled upd...</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green community dishwasher central air condit...</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onsite golf course guest suite available four...</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shelby township newest luxury apartment  code...</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           processed  price\n",
       "0   private patio balcony bbq area business cente...   1350\n",
       "1   bedroom  code link post totally remodeled upd...   1100\n",
       "2   green community dishwasher central air condit...    980\n",
       "3   onsite golf course guest suite available four...   1055\n",
       "4   shelby township newest luxury apartment  code...   1650"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2f159a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1388.057408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>938.570071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>860.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price\n",
       "count   9807.000000\n",
       "mean    1388.057408\n",
       "std      938.570071\n",
       "min      510.000000\n",
       "25%      860.000000\n",
       "50%     1100.000000\n",
       "75%     1500.000000\n",
       "max    14001.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata.describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d71d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "processed    object\n",
       "price         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0679813c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(5, 10)}, font_scale = 1.5, style = 'whitegrid')\n",
    "sns.boxplot (data = rdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f74574b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>price</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>private patio balcony bbq area business cente...</td>\n",
       "      <td>1350</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bedroom  code link post totally remodeled upd...</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green community dishwasher central air condit...</td>\n",
       "      <td>980</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onsite golf course guest suite available four...</td>\n",
       "      <td>1055</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shelby township newest luxury apartment  code...</td>\n",
       "      <td>1650</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           processed  price  label\n",
       "0   private patio balcony bbq area business cente...   1350      4\n",
       "1   bedroom  code link post totally remodeled upd...   1100      3\n",
       "2   green community dishwasher central air condit...    980      2\n",
       "3   onsite golf course guest suite available four...   1055      3\n",
       "4   shelby township newest luxury apartment  code...   1650      5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def price_label (x):\n",
    "    \n",
    "    if x > 0 and x <= 500:\n",
    "        return 0 \n",
    "    elif x > 500 and x <= 800:\n",
    "        return 1\n",
    "    elif x > 800 and x <= 1000:\n",
    "        return 2\n",
    "    elif x > 1000 and x <= 1200:\n",
    "        return 3\n",
    "    elif x > 1200 and x <= 1500:\n",
    "        return 4\n",
    "    elif x > 1500 and x <= 1800:\n",
    "        return 5\n",
    "    elif x > 1800 and x <= 2000:\n",
    "        return 6\n",
    "    elif x > 2000 and x <= 2500:\n",
    "        return 7\n",
    "    elif x > 2500 and x <= 4000:\n",
    "        return 8\n",
    "    elif x > 4000 and x <= 6000:\n",
    "        return 9\n",
    "    elif x > 6000 and x <= 8000:\n",
    "        return 10\n",
    "    elif x > 8000 and x <= 12000:\n",
    "        return 11\n",
    "    else:\n",
    "#       x > 12000\n",
    "        return 12\n",
    "\n",
    "rdata ['label'] = rdata ['price'].apply (price_label)\n",
    "\n",
    "rdata.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cffafaa",
   "metadata": {},
   "source": [
    "### Splitting into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58cc899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split (rdata ['processed'], rdata ['label'], test_size = 0.2, random_state = 1996)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d16e43a",
   "metadata": {},
   "source": [
    "### Let's check how well a base classifier model would do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e50b46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "46d31096",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer (ngram_range = (1, 2), min_df = 5)\n",
    "\n",
    "x_train_trans = vectorizer.fit_transform (x_train)\n",
    "x_test_trans = vectorizer.transform (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "37838850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy: 0.5524974515800204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NBmodel = MultinomialNB()\n",
    "\n",
    "NBmodel.fit (x_train_trans, y_train)\n",
    "y_pred_NB = NBmodel.predict (x_test_trans)\n",
    "\n",
    "acc_NB = accuracy_score (y_test, y_pred_NB)\n",
    "print ('NB Accuracy:', acc_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bb963037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier accuracy: 0.5056065239551478\n"
     ]
    }
   ],
   "source": [
    "## ANN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPmodel = MLPClassifier (solver = 'lbfgs', hidden_layer_sizes = (10, 20, 10))\n",
    "\n",
    "MLPmodel.fit (x_train_trans, y_train)\n",
    "y_pred_MLP = MLPmodel.predict (x_test_trans)\n",
    "\n",
    "acc_MLP = accuracy_score (y_test, y_pred_MLP)\n",
    "print ('MLP Classifier accuracy:', acc_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f412c",
   "metadata": {},
   "source": [
    "### Let's see how well the BERT model can do in comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4052f01",
   "metadata": {},
   "source": [
    "### Training a BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58a1abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained ('distilbert-base-uncased')\n",
    "\n",
    "# Padding and truncation of data\n",
    "inputs = tokenizer (x_train.tolist(), padding = 'max_length', truncation = True)\n",
    "\n",
    "labels = y_train.tolist ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02525bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorize (torch.utils.data.Dataset):\n",
    "    def __init__ (self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__ (self, idx):\n",
    "        item = {key: torch.tensor (val [idx]) for key, val in self.encodings.items ()}\n",
    "        item ['labels'] = torch.tensor (self.labels [idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__ (self):\n",
    "        return len (self.labels)\n",
    "    \n",
    "train_dataset = tensorize (inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89b52bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([  101,  7997,  5527,  8102, 11980,  3229,  3642,  4957,  2695,  2148,\n",
      "         8904,  4545,  8987,  2326,  9788,  3643,  4010,  2451,  4382,  2881,\n",
      "         3749,  6020,  2542,  3325,  2148,  8904,  5292,  2392,  2067,  3332,\n",
      "         7524,  4346,  2422,  2250,  2100,  7224,  5957,  2094, 10119,  9669,\n",
      "         2392,  2311,  9324,  2312, 22944,  2330,  2686,  3584,  2457,  4632,\n",
      "        12228, 16125,  9394,  2284, 13240,  4665,  3545,  5297,  2346,  3481,\n",
      "         2395,  3640,  3622,  3229,  3518,  2082,  6023,  2415,  2350, 11194,\n",
      "         4592, 10439, 15204,  3401,  9920,  5527,  3229,  8114,  1044, 24887,\n",
      "         3177,  4274,  3229, 12695,  2181,  9346,  2265,  2592,  3942, 20874,\n",
      "        11343,  3395,  2689,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(3)}\n"
     ]
    }
   ],
   "source": [
    "print (train_dataset.__getitem__(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66b5be30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\svveg/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\svveg/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bertmodel = DistilBertForSequenceClassification.from_pretrained ('distilbert-base-uncased', num_labels = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92a7f6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device ('cuda:0' if torch.cuda.is_available () else 'cpu')\n",
    "bertmodel.to (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21795042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "C:\\Users\\svveg\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7845\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 982\n",
      "  Number of trainable parameters = 66963469\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='982' max='982' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [982/982 12:35:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.905500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.086800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.038200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.080600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.983600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.932600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.082800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.953900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.961900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.128800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.989700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.920400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.880900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.794400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.840900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.985900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.825200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.825900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.706400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.615800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.798900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.679800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.832900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.794800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.706400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.791800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.884500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.616700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.773900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.704700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.741700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.695300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.906700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.670400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.667200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.741800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.628300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.907900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.808200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.773300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.832900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.869500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.938500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=982, training_loss=0.8987802611834649, metrics={'train_runtime': 45362.6157, 'train_samples_per_second': 0.346, 'train_steps_per_second': 0.022, 'total_flos': 2078821206005760.0, 'train_loss': 0.8987802611834649, 'epoch': 2.0})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments (output_dir = './results',\n",
    "                                   num_train_epochs = 2,\n",
    "                                   per_device_train_batch_size = 16,\n",
    "                                   per_device_eval_batch_size = 64,\n",
    "                                   warmup_steps = 500,\n",
    "                                   weight_decay = 0.00001,\n",
    "                                   logging_dir = './logs',\n",
    "                                   logging_steps = 10,\n",
    "                                  )\n",
    "trainer = Trainer (model = bertmodel,\n",
    "                  args = training_args,\n",
    "                  train_dataset = train_dataset,\n",
    "                  )\n",
    "\n",
    "trainer.train ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4892828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = []\n",
    "\n",
    "for i in x_train:\n",
    "    test_encoding1 = tokenizer (i, truncation = True, padding = True)\n",
    "    input_ids = torch.tensor (test_encoding1 ['input_ids']).to (device)\n",
    "    attention_mask = torch.tensor (test_encoding1 ['attention_mask']).to (device)\n",
    "    op = bert_pred (test_encoding1)\n",
    "    preds1.append (op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7914e0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7533460803059273\n",
      "[[1495   64   11   12    1    0    0   17    0    0    0    0]\n",
      " [ 111 1323  208   54    4    0    2    5    0    0    0    0]\n",
      " [  37  140  999  215    9    2    1    3    0    0    0    0]\n",
      " [  23   34  146  855   75   32   11   37    0    0    0    0]\n",
      " [   1   17   11   84  313   10   18   47    0    0    0    0]\n",
      " [   0    1    8   36   39   64   25   29    0    0    0    0]\n",
      " [   0    2    1   17   18   17   69  147    2    0    0    0]\n",
      " [   1    2    3   10    7    4   10  720   27    0    0    0]\n",
      " [   0    0    0    1    3    1    4   60   72    0    0    0]\n",
      " [   0    0    0    0    0    0    0    4    1    0    0    0]\n",
      " [   1    2    1    1    0    0    0    3    0    0    0    0]\n",
      " [   0    1    0    1    1    0    0    2    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score (y_train, preds1))\n",
    "print (confusion_matrix (y_train, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbde80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = []\n",
    "\n",
    "for i in x_test:\n",
    "    test_encoding1 = tokenizer (i, truncation = True, padding = True)\n",
    "    input_ids = torch.tensor (test_encoding1 ['input_ids']).to (device)\n",
    "    attention_mask = torch.tensor (test_encoding1 ['attention_mask']).to (device)\n",
    "    op = bert_pred (test_encoding1)\n",
    "    preds2.append (op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94a5425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6253822629969419\n",
      "[[342  39  14  13   0   0   0  10   0   0   0]\n",
      " [ 58 249  68  28   7   1   0   5   0   0   0]\n",
      " [ 16  56 193  59   4   3   0   7   0   0   0]\n",
      " [ 14  10  60 185  14   7   5  13   0   0   0]\n",
      " [  3   5   9  34  61   5   5  16   0   0   0]\n",
      " [  1   3   2  13   9   9   5  14   0   0   0]\n",
      " [  1   0   4  10   4   7  15  21   0   0   0]\n",
      " [  1   1   1   6   5   4   8 158   6   0   0]\n",
      " [  0   0   0   0   0   0   0  17  15   0   0]\n",
      " [  0   1   0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   1   0   0   1   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score (y_test, preds2))\n",
    "cf = confusion_matrix (y_test, preds2)\n",
    "print (cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35c31d",
   "metadata": {},
   "source": [
    "### Accuracy much higher in comparison. Can be trained for more epochs on a system with GPU to achieve much better accuracy. Even now, the misclassifications are very close to the correct price labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae360e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
